#!/bin/bash
#SBATCH --partition=t1small
#SBATCH --ntasks=24
#SBATCH --tasks-per-node=24
#If running on the bio or analysis queue add:
####SBATCH --mem=214G
#SBATCH --mail-user=wwinnett@alaska.edu
#SBATCH --mail-type=BEGIN
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --job-name="panmeta_align_canu_lr-log"
#SBATCH --output=data/canu/logs/polished/log_slurm_canu_lr-log_%j.log
#SBATCH --error=data/canu/logs/polished/log_slurm_canu_lr-log_%j_err.log

## Clean out any modules, then reload slurm
# Since conda will be used, no other modules will be loaded
module purge
module load slurm

ulimit -l unlimited

eval "$(conda shell.bash hook)"

conda activate asm_miniasm
mkdir -p data/canu/lr-log/polished/

minimap2 -ax map-ont -t 24 data/canu/lr-log/lr-log_task.contigs.fasta data/raw/lr-log/Zymo-GridION-LOG-BB-SN.fq > data/canu/lr-log/polished/overlap_canu_lr-log.paf