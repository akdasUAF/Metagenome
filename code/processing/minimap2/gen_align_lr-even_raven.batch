#!/bin/bash
#SBATCH --partition=t1small
#SBATCH --ntasks=24
#SBATCH --tasks-per-node=24
#If running on the bio or analysis queue add:
####SBATCH --mem=214G
#SBATCH --mail-user=wwinnett@alaska.edu
#SBATCH --mail-type=BEGIN
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --job-name="panmeta_asm_megahit_sr-even_t1standard"
#SBATCH --output=data/megahit/logs/log_slurm_megahit_sr-even_%j.log
#SBATCH --error=data/megahit/logs/log_slurm_megahit_sr-even_err_%j.log

## Clean out any modules, then reload slurm
# Since conda will be used, no other modules will be loaded
module purge
module load slurm

ulimit -l unlimited

eval "$(conda shell.bash hook)"


conda activate asm_miniasm

minimap2 -ax map-ont -t 24 data/raven/lr-even/assembly_raven_lr-even.fasta data/raw/lr-even/lr-even_raw.fastq > data/raven/lr-even/polished/overlap_raven_lr-even.paf