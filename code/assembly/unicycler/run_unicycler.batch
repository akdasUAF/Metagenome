#!/bin/bash
#SBATCH --partition=t1small
#SBATCH --ntasks=1                # Total number of tasks
#SBATCH --cpus-per-task=24 
#SBATCH --mem=64G 
#SBATCH --mail-user=wwinnett@alaska.edu
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --job-name="unicycler_bench" # Job name for Slurm
#SBATCH --output=logs/slurm_unicycler_bench_%j.log # Slurm stdout log
#SBATCH --error=logs/slurm_unicycler_bench_err_%j.log # Slurm stderr log

# --- Conda Initialization ---
CONDA_BASE=$(conda info --base)
if [ -f "${CONDA_BASE}/etc/profile.d/conda.sh" ]; then
    . "${CONDA_BASE}/etc/profile.d/conda.sh"
    echo "Conda initialized from ${CONDA_BASE}/etc/profile.d/conda.sh"
else
    echo "ERROR: conda.sh not found at ${CONDA_BASE}/etc/profile.d/conda.sh."
    echo "Please ensure Conda is installed and 'conda init bash' has been run."
    exit 1
fi

# --- 1. User Configuration & Argument Parsing ---
# This script orchestrates Unicycler assembly with integrated benchmarking.
# It directly finds the FASTQ files (for a single paired-end library) and constructs the Unicycler command,
# then calls 'benchmark.bash' to monitor system performance.
#
# Arguments expected when submitting this Slurm script:
# $1: <dataset_name>             (e.g., "sr-even") - A descriptive name for your dataset.
#                                 Used for organizing output directories and benchmarking logs.
# $2: <fastq_input_directory>    (e.g., "data/raw/sr-even/raw/test1/")
#                                 This directory MUST contain exactly one pair of FASTQ files
#                                 (e.g., sample_R1_trimmed.fastq.gz, sample_R2_trimmed.fastq.gz).
# $3: <assembly_output_subfolder_name> (e.g., "unicycler_assembly_run1")
#                                 A unique name for the specific output folder for *this* assembly run.
#                                 This folder will be created inside 'data/unicycler/<dataset_name>/'.
# $4: <benchmarking_task_name>   (e.g., "unicycler_assembly_sr-even_run1")
#                                 A unique name to identify this particular benchmarking run within the dataset.

if [ "$#" -ne 4 ]; then
    echo "Usage: sbatch $0 <dataset_name> <fastq_input_directory> <assembly_output_subfolder_name> <benchmarking_task_name>"
    echo "Example: sbatch $0 sr-even data/raw/sr-even/raw/test1/ test1 unicycler_bench_sr-even_run1"
    exit 1
fi

declare -r DATASET_NAME="$1"
declare -r FASTQ_INPUT_DIR="$2"
declare -r ASSEMBLY_OUTPUT_SUBFOLDER_NAME="$3"
declare -r BENCHMARKING_TASK_NAME="$4"

# --- 2. Define Paths to other scripts and derived output locations ---
declare -r BENCHMARKING_SCRIPT="code/benchmarking/benchmark.bash"
# CHANGED: Path to your unicycler.sh wrapper
declare -r UNICYCLER_RUN_SCRIPT="code/assembly/unicycler/unicycler.sh" 

# Base directory for all assembly outputs - CHANGED for Unicycler
declare -r ASSEMBLY_BASE_DIR="data/unicycler"

# The full path to the specific output directory for *this* assembly run
declare -r CURRENT_ASSEMBLY_OUTPUT_DIR="${ASSEMBLY_BASE_DIR}/${DATASET_NAME}/${ASSEMBLY_OUTPUT_SUBFOLDER_NAME}"

# The benchmarking script will handle creating its own log directory structure:
# data/logs/${DATASET_NAME}/${BENCHMARKING_TASK_NAME}/
declare -r BENCHMARKING_LOG_DIR="data/logs/${DATASET_NAME}/${BENCHMARKING_TASK_NAME}"

# --- 3. Input Validation ---
if [ ! -d "${FASTQ_INPUT_DIR}" ]; then
    echo "ERROR: FASTQ input directory not found: ${FASTQ_INPUT_DIR}"
    echo "Please ensure the directory exists and contains your FASTQ files."
    exit 1
fi
if [ ! -f "${BENCHMARKING_SCRIPT}" ]; then
    echo "ERROR: Benchmarking script not found: ${BENCHMARKING_SCRIPT}"
    echo "Expected at: ${BENCHMARKING_SCRIPT}"
    exit 1
fi
# CHANGED: Check for unicycler.sh instead of metaspades.sh
if [ ! -f "${UNICYCLER_RUN_SCRIPT}" ]; then
    echo "ERROR: Unicycler run script not found: ${UNICYCLER_RUN_SCRIPT}"
    echo "Expected at: ${UNICYCLER_RUN_SCRIPT}"
    exit 1
fi

echo "Script started at $(date)"
echo "Configuration:"
echo "  Dataset Name: ${DATASET_NAME}"
echo "  FASTQ Input Directory: ${FASTQ_INPUT_DIR}"
echo "  Assembly Output Subfolder Name: ${ASSEMBLY_OUTPUT_SUBFOLDER_NAME}"
echo "  Benchmarking Task Name: ${BENCHMARKING_TASK_NAME}"
echo "  Full Assembly Output Directory: ${CURRENT_ASSEMBLY_OUTPUT_DIR}"
echo "  Benchmarking Log Directory: ${BENCHMARKING_LOG_DIR}"
echo ""

echo "Current memory usage before assembly job submission:"
free -h

# --- 4. Prepare base output directory for assembly ---
mkdir -p "${ASSEMBLY_BASE_DIR}/${DATASET_NAME}" || { echo "ERROR: Could not create base assembly directory ${ASSEMBLY_BASE_DIR}/${DATASET_NAME}"; exit 1; }
mkdir -p "${CURRENT_ASSEMBLY_OUTPUT_DIR}" || { echo "ERROR: Could not create assembly output directory ${CURRENT_ASSEMBLY_OUTPUT_DIR}"; exit 1; }

# --- 5. Determine memory limit for Unicycler (informative only for SBATCH --mem) ---
# Unicycler's memory usage is primarily governed by the internal SPAdes run,
# which typically respects system limits or its own internal configuration.
# The SBATCH --mem flag is crucial for allocating resources on the cluster.
# We will NOT pass a specific memory flag to the unicycler.sh wrapper,
# as Unicycler doesn't have a direct top-level `-m` for memory like MetaSPAdes.
REQUESTED_MEM_GB=$(echo "${SLURM_MEM_PER_NODE}" | sed 's/G//I') # Remove 'G' (case-insensitive) if present
if ! [[ "$REQUESTED_MEM_GB" =~ ^[0-9]+$ ]]; then
    echo "Warning: SLURM_MEM_PER_NODE ('${SLURM_MEM_PER_NODE}') is not a simple integer in G. Attempting conversion assuming MB." >&2
    # If it's not a direct GB value, assume MB and convert
    REQUESTED_MEM_GB=$((SLURM_MEM_PER_NODE / 1024))
    if [ "$REQUESTED_MEM_GB" -eq 0 ]; then
        echo "Error: Could not determine valid memory limit from SLURM_MEM_PER_NODE. Set to 0." >&2
        REQUESTED_MEM_GB=0 # Default to 0 if conversion fails or results in 0
    else
        echo "Converted SLURM_MEM_PER_NODE (MB) to ${REQUESTED_MEM_GB} GB for Unicycler's resource allocation."
    fi
fi

if [ "$REQUESTED_MEM_GB" -eq 0 ]; then
    echo "WARNING: Could not determine memory limit in GB from SLURM_MEM_PER_NODE. Unicycler's internal SPAdes might use default."
fi

echo "Determined memory for Unicycler job (SBATCH allocation): ${REQUESTED_MEM_GB} GB"
echo ""


# --- 6. Construct the command to be passed to the benchmarking script ---
# This command will directly run unicycler.sh within the 'asm_unicycler' conda environment.
# unicycler.sh expects:
# <path_to_fastq_dir> <path_output_dir> <num_threads>

declare UNICYCLER_COMMAND_ARGS=""
UNICYCLER_COMMAND_ARGS+="\"${FASTQ_INPUT_DIR}\" "
UNICYCLER_COMMAND_ARGS+="\"${CURRENT_ASSEMBLY_OUTPUT_DIR}\" "
UNICYCLER_COMMAND_ARGS+="${SLURM_CPUS_PER_TASK}" # Threads (NO TRAILING SPACE)

# CHANGED: Use the new unicycler.sh script and the unicycler conda environment
declare UNICYCLER_COMMAND_TO_RUN_STRING="conda run -n asm_unicycler bash ${UNICYCLER_RUN_SCRIPT} ${UNICYCLER_COMMAND_ARGS}"

echo "Command that will be passed to benchmarking script for execution:"
echo "${BENCHMARKING_SCRIPT} \"${UNICYCLER_COMMAND_TO_RUN_STRING}\" \"${DATASET_NAME}\" \"${BENCHMARKING_TASK_NAME}\""
echo ""

# --- 7. Execute the benchmarking script ---
set -x # Enable command echoing for debugging the overall execution flow
"${BENCHMARKING_SCRIPT}" "${UNICYCLER_COMMAND_TO_RUN_STRING}" "${DATASET_NAME}" "${BENCHMARKING_TASK_NAME}"
set +x # Disable command echoing

if [ $? -ne 0 ]; then
    echo "ERROR: The benchmarking/Unicycler assembly process failed. Exit status: $?."
    echo "Check logs in data/logs/${DATASET_NAME}/${BENCHMARKING_TASK_NAME}/ for more details, especially log_full_<task>_<dataset>.log."
    exit 1
fi

echo "Unicycler assembly with benchmarking completed successfully."
echo "Assembly output located in: ${CURRENT_ASSEMBLY_OUTPUT_DIR}"
echo "Benchmarking logs (dool, full console output) in: data/logs/${DATASET_NAME}/${BENCHMARKING_TASK_NAME}/"
echo "Script finished at $(date)"s