#!/usr/bin/env bash
#SBATCH --partition=t1small       # Or your preferred partition
#SBATCH --ntasks=1                # Total number of tasks
#SBATCH --cpus-per-task=24        # Number of CPU cores per task (adjust as needed for --threads)
#SBATCH --mem=64G                 # Total memory for the job (adjust based on assembly/read size)
#SBATCH --mail-user=wwinnett@alaska.edu
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --job-name=map2reads
#SBATCH --output=logs/slurm_map2reads_%j.log
#SBATCH --error=logs/slurm_mmap2reads_%j.log.err

# Set unlimited locked memory for processes (good for large jobs)
ulimit -l unlimited
ulimit -n 65536 # Increase open file descriptor limit if needed

set -euo pipefail

module load slurm
module load GCC/11.3.0
module load SAMtools/1.17
module load IPython/8.5.0
module load BCFtools/1.17
module load HTSlib/1.17

# --- Conda Initialization ---
CONDA_BASE=$(conda info --base)
if [ -f "${CONDA_BASE}/etc/profile.d/conda.sh" ]; then
    . "${CONDA_BASE}/etc/profile.d/conda.sh"
    echo "Conda initialized from ${CONDA_BASE}/etc/profile.d/conda.sh"
else
    echo "ERROR: conda.sh not found at ${CONDA_BASE}/etc/profile.d/conda.sh."
    echo "Please ensure Conda is installed and 'conda init bash' has been run."
    exit 1
fi




# Activate your Medaka conda environment
conda activate align_minimap2


if [ $# -ne 5 ]; then
  echo "Usage: $0 <sample> <assembler> <run> <contigs_fasta> <aligned_bam>"
  exit 1
fi

sample=$1
assembler=$2
run=$3
contigs_fasta=$4
aligned_bam=$5

workdir="data/${assembler}/${sample}/${run}/map"
mkdir -p "${workdir}"






# Filenames for intermediate and final outputs
bcf_calls="${workdir}/${sample}_${assembler}_${run}_calls.bcf"
final_fastq="${workdir}/final-contigs.fastq"


echo "Sample: ${sample}"
echo "Assembler: ${assembler}"
echo "Run: ${run}"
echo "Contigs FASTA: ${contigs_fasta}"
echo "Aligned BAM: ${aligned_bam}"
echo "Output directory: ${workdir}"






## Step 1: Extract contigâ†’read mappings from BAM
echo ">>> Performing Pileup..."
samtools mpileup -f ${contigs_fasta} -Ou ${aligned_bam} | bcftools call -mv -Ob -o ${bcf_calls}


## Step 2: Derive unique read IDs
echo ">>> Perfoming Index..."
bcftools index ${bcf_calls}

## Step 3: Subset raw FASTQ by read IDs
echo ">>> Subsetting FASTQ..."
bcftools view ${bcf_calls} \
  | vcfutils.pl vcf2fq -d 1 -D 100 \
  > ${final_fastq}

echo "Finished. Final FASTQ: ${final_fastq}"
